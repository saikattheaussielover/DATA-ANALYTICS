{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8CYl_N9jYNG"
      },
      "source": [
        "# Image Classification by MLP - Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maxGhjMWjYNH"
      },
      "source": [
        "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PH1EF1qjYNI"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3z4rz6kjYNI",
        "outputId": "25eaf0d7-1159-48e4-8cb3-dd2db96afd62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "#TODO: load dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#TODO: Resample the dataset if needed\n",
        "# X_train = ...\n",
        "# y_train = ...\n",
        "# X_test = ...\n",
        "# y_test = ...\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RMXNMsSjYNJ"
      },
      "source": [
        "This dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H99C9Jz0jYNJ"
      },
      "source": [
        "Now begin by exploring the data. Try to display some images with the associated label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "PUiyRX0sjYNJ",
        "outputId": "2b4a4183-09ed-4a79-e725-30285d453853"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "# np.random.seed(0)\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap='gray_r')\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7250yqRjYNK"
      },
      "source": [
        "**Before going further**: what methods could you use to perform such a classification task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW_0VXYijYNK"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4jCinBGjYNK"
      },
      "source": [
        "The first method you will try is using neural networks. First step is the data preparation: data rescaling, label preparation.\n",
        "\n",
        "Hint: you can use the Keras function `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwLm9wa_jYNK",
        "outputId": "11bc11c1-4bb3-4f8b-a859-6700a91e5e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 784)\n"
          ]
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "# TODO: reshape the image data (2D array) into input 1D array for a neural network\n",
        "print(np.shape(X_train_norm))\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], np.prod(X_train_norm.shape[1:]))\n",
        "print(np.shape(X_train_norm))\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], np.prod(X_test_norm.shape[1:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlHZavO_jYNK"
      },
      "source": [
        "Next step: model building with Keras. Build your neural network architecture. At first, I would recommend a light architecture: no more than 2 hidden layers, with about 10 units per layer. Put that model into a function, so that you can reuse it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UYmqxQrjYNL",
        "outputId": "bec46060-1cdc-4d1e-81a2-013390aade65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 10)                7850      \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def my_model(input_dim):\n",
        "    # Create the Sequential object\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add 2 dense layers with 10 neurons each using sigmoid or relu activation\n",
        "    model.add(Dense(10, input_dim=input_dim, activation=\"sigmoid\"))\n",
        "    model.add(Dense(10, activation=\"sigmoid\"))\n",
        "\n",
        "    # Add the output layer with one unit: the predicted result\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "my_model(X_train_norm.shape[1]).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0emzIwcjYNL"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m81321djYNL",
        "outputId": "96d6d88a-9b62-48a9-87ee-247ba4756f54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 3s 4ms/step - loss: 1.9689 - accuracy: 0.4735\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.2992 - accuracy: 0.6578\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.9277 - accuracy: 0.6980\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.7729 - accuracy: 0.7393\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.6889 - accuracy: 0.7731\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.6204 - accuracy: 0.8025\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5614 - accuracy: 0.8210\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.5208 - accuracy: 0.8295\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4924 - accuracy: 0.8368\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4720 - accuracy: 0.8414\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4554 - accuracy: 0.8450\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4428 - accuracy: 0.8483\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4326 - accuracy: 0.8514\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4232 - accuracy: 0.8528\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4150 - accuracy: 0.8564\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4081 - accuracy: 0.8586\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4023 - accuracy: 0.8595\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3973 - accuracy: 0.8619\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3925 - accuracy: 0.8629\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3884 - accuracy: 0.8648\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3848 - accuracy: 0.8648\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3810 - accuracy: 0.8666\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3774 - accuracy: 0.8678\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3748 - accuracy: 0.8681\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3715 - accuracy: 0.8697\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3688 - accuracy: 0.8707\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3659 - accuracy: 0.8717\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3648 - accuracy: 0.8720\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3616 - accuracy: 0.8735\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3593 - accuracy: 0.8741\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3582 - accuracy: 0.8740\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3556 - accuracy: 0.8743\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3532 - accuracy: 0.8752\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3510 - accuracy: 0.8755\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3494 - accuracy: 0.8772\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3474 - accuracy: 0.8777\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3461 - accuracy: 0.8773\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3446 - accuracy: 0.8785\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3433 - accuracy: 0.8791\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3420 - accuracy: 0.8800\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3409 - accuracy: 0.8803\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3386 - accuracy: 0.8803\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3373 - accuracy: 0.8810\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3361 - accuracy: 0.8811\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3352 - accuracy: 0.8819\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3340 - accuracy: 0.8818\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3337 - accuracy: 0.8822\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3319 - accuracy: 0.8827\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3306 - accuracy: 0.8838\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3298 - accuracy: 0.8838\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3287 - accuracy: 0.8834\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3285 - accuracy: 0.8838\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3273 - accuracy: 0.8846\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3252 - accuracy: 0.8846\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3262 - accuracy: 0.8847\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3242 - accuracy: 0.8857\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3235 - accuracy: 0.8862\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3242 - accuracy: 0.8852\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3225 - accuracy: 0.8858\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3216 - accuracy: 0.8864\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3195 - accuracy: 0.8874\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3208 - accuracy: 0.8863\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3198 - accuracy: 0.8875\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3188 - accuracy: 0.8872\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3189 - accuracy: 0.8869\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3173 - accuracy: 0.8868\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3168 - accuracy: 0.8869\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3153 - accuracy: 0.8884\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3149 - accuracy: 0.8878\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3154 - accuracy: 0.8878\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3142 - accuracy: 0.8885\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3142 - accuracy: 0.8881\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3132 - accuracy: 0.8889\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3135 - accuracy: 0.8888\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3124 - accuracy: 0.8897\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3116 - accuracy: 0.8895\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3113 - accuracy: 0.8898\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3107 - accuracy: 0.8895\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3097 - accuracy: 0.8909\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3097 - accuracy: 0.8902\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.3087 - accuracy: 0.8916\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3091 - accuracy: 0.8899\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3077 - accuracy: 0.8907\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3075 - accuracy: 0.8904\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3077 - accuracy: 0.8899\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3068 - accuracy: 0.8903\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3060 - accuracy: 0.8917\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3063 - accuracy: 0.8906\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3052 - accuracy: 0.8912\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3057 - accuracy: 0.8909\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3035 - accuracy: 0.8923\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3055 - accuracy: 0.8912\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3038 - accuracy: 0.8922\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3039 - accuracy: 0.8917\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3030 - accuracy: 0.8921\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3030 - accuracy: 0.8923\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3008 - accuracy: 0.8927\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3015 - accuracy: 0.8927\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3018 - accuracy: 0.8920\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3010 - accuracy: 0.8933\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1dfcd8e380>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
        "\n",
        "# TODO: Compile and fit your model\n",
        "model = my_model(X_train_norm.shape[1])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_norm, y_train_cat, epochs=100, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh_ln4oYjYNL"
      },
      "source": [
        "Once your model has been trained, compute the accuracy (and other metrics if you want) on the train and test dataset.\n",
        "\n",
        "Be careful, Keras returns softmax output (so an array of 10 values between 0 and 1, for which the sum is equal to 1). To compute correctly the accuracy, you have to convert that array into a categorical array with zeros and a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkLANYOhjYNL",
        "outputId": "112a07d4-3447-417e-dcc6-59586cee3995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with NN: 0.8910666704177856\n",
            "accuracy on test with NN: 0.8503000140190125\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "print('accuracy on train with NN:', model.evaluate(X_train_norm, y_train_cat, verbose=0)[1])\n",
        "print('accuracy on test with NN:', model.evaluate(X_test_norm, y_test_cat, verbose=0)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgorCi3ejYNL"
      },
      "source": [
        "What do you think of those results? Can you improve it by changing the number of layers? Of units per layer? The number of epochs? The activation functions?\n",
        "\n",
        "The accuracy is good, but it could be changed by changing number of layers, time for running could be shortened depending on epochs. \n",
        "\n",
        "You should try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTm6zYjWjYNM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-qMCn5HjYNM"
      },
      "source": [
        "In order to compare your results with more traditional machine learning methods, you will do this work with another method: a PCA followed by a classification model (of your choice). Of course, you can perform hyperparameter optimization using a gridsearch on that model!\n",
        "\n",
        "Fit your model and display the performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2Ze-AAWjYNM"
      },
      "outputs": [],
      "source": [
        "# TODO: Redo the classification with PCA and classification model\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.9)\n",
        "\n",
        "pca.fit(X_train_norm)\n",
        "X_train_pca = pca.transform(X_train_norm)\n",
        "X_test_pca = pca.transform(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dsOteN-jYNM",
        "outputId": "24b8d5cf-f19a-4c14-fa86-ed060b4b752a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score with RF on train 1.0\n",
            "score with RF on test 0.8612\n"
          ]
        }
      ],
      "source": [
        "# TODO: use any classifier you want\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_pca, y_train)\n",
        "\n",
        "print('score with RF on train', rf.score(X_train_pca, y_train))\n",
        "print('score with RF on test', rf.score(X_test_pca, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF-Cuke2jYNM"
      },
      "source": [
        "Are the performances different? Can you explain why?\n",
        "\n",
        "Yes, the accuracy has increased. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOCNcI67jYNM"
      },
      "source": [
        "If you still have time, you could try to use scikit-learn's `Pipeline` to perform the hyperparameter optimization jointly on the PCA and the classification model. This might improve your performances."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}